{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils # when visualing out poses\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: #.Pose access pose estimation model, #min_tracking_confidence tracks state\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() # frame is image from camera\n",
    "        \n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # save memory\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image) # image here is RGB\n",
    "        \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) # image here is BGR\n",
    "        \n",
    "        cv2.imshow('Mediappipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://mediapipe.dev/images/mobile/pose_tracking_full_body_landmarks.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: #.Pose access pose estimation model, #min_tracking_confidence tracks state\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() # frame is image from camera\n",
    "        \n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # save memory\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image) # image here is RGB\n",
    "        \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark # hold landamrks. including x,y,z. Use this for calculating angles\n",
    "            # print(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX])\n",
    "            # Filter out landmarks with low visibility\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) # image here is BGR\n",
    "        \n",
    "        cv2.imshow('Mediappipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose.Pose??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.6142386\n",
       "y: 2.3633475\n",
       "z: -0.65662456\n",
       "visibility: 0.0020882552"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value] # why does this have value even tho it didn't detect it. if visiblility is low, don't save the position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.62809384\n",
       "y: 1.1210781\n",
       "z: -0.37526324\n",
       "visibility: 0.41440323"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.6687571\n",
       "y: 1.2022107\n",
       "z: -0.8656362\n",
       "visibility: 0.36659306"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.5560192\n",
       "y: 1.0103874\n",
       "z: -1.1541002\n",
       "visibility: 0.3021175"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # Frist\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1] - b[1], c[0] -b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0/np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "        \n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: #.Pose access pose estimation model, #min_tracking_confidence tracks state\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() # frame is image from camera\n",
    "        \n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # save memory\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image) # image here is RGB\n",
    "        \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark # hold landamrks. including x,y,z. Use this for calculating angles\n",
    "            # print(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX])\n",
    "            # Filter out landmarks with low visibility\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]    \n",
    "            \n",
    "            # hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            # shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            # elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]   \n",
    "            \n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualizeq\n",
    "            cv2.putText(image, \n",
    "                        str(angle),\n",
    "                        tuple(np.multiply(elbow, [640, 480]).astype(int)), # controal [640, 480] to window size\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) # image here is BGR\n",
    "        \n",
    "        cv2.imshow('Mediappipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curl Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## Curl counter variables\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "## setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: #.Pose access pose estimation model, #min_tracking_confidence tracks state\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() # frame is image from camera\n",
    "        \n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # save memory\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image) # image here is RGB\n",
    "        \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark # hold landamrks. including x,y,z. Use this for calculating angles\n",
    "            # print(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX])\n",
    "            # Filter out landmarks with low visibility\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]    \n",
    "            \n",
    "            # hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            # shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            # elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]   \n",
    "            \n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualize\n",
    "            cv2.putText(image, \n",
    "                        str(angle),\n",
    "                        tuple(np.multiply(elbow, [640, 480]).astype(int)), # controal [640, 480] to window size\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "            if angle < 30 and stage == 'down':\n",
    "                stage = 'up'\n",
    "                counter += 1\n",
    "                print(counter) \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render curl counter\n",
    "        cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "        \n",
    "        cv2.putText(image, 'REPS', (15,20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        cv2.putText(image, str(counter),\n",
    "                    (10,70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) # image here is BGR\n",
    "        \n",
    "        cv2.imshow('Mediappipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize angle vs frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'angle')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cap = cv2.VideoCapture('\"Steph Curry.mp4\"')\n",
    "\n",
    "# Curl counter variables\n",
    "# counter = 0\n",
    "# stage = None\n",
    "\n",
    "times = []\n",
    "time = 0\n",
    "left_elbow_angles = []\n",
    "left_shoulder_angles = []\n",
    "## setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: #.Pose access pose estimation model, #min_tracking_confidence tracks state\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() # frame is image from camera\n",
    "        \n",
    "        frame_width = int(cap.get())\n",
    "        \n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # save memory\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image) # image here is RGB\n",
    "        \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark # hold landamrks. including x,y,z. Use this for calculating angles\n",
    "            # print(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX])\n",
    "            # Filter out landmarks with low visibility\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]    \n",
    "            \n",
    "            # shoulder angle\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            \n",
    "            # left_ = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "\n",
    "            # hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            # shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            # elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]   \n",
    "            \n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            left_shoulder_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "            \n",
    "            if time % 5 == 0:\n",
    "                left_elbow_angles.append(left_elbow_angle)\n",
    "                left_shoulder_angles.append(left_shoulder_angle)\n",
    "                \n",
    "                times.append(time)\n",
    "            time+=1\n",
    "            \n",
    "            # Visualize\n",
    "            cv2.putText(image, \n",
    "                        str(angle),\n",
    "                        tuple(np.multiply(elbow, [640, 480]).astype(int)), # controal [640, 480] to window size\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "            if angle < 30 and stage == 'down':\n",
    "                stage = 'up'\n",
    "                counter += 1\n",
    "                print(counter) \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render curl counter\n",
    "        cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "        \n",
    "        cv2.putText(image, 'REPS', (15,20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        cv2.putText(image, str(counter),\n",
    "                    (10,70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) # image here is BGR\n",
    "        \n",
    "        cv2.imshow('Mediappipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "plt.plot(times, left_elbow_angles, color='b', label = 'left_elbow')\n",
    "plt.plot(times, left_shoulder_angles, color='r', label='left_shoulder')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('angle')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('3d-body-demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "027937559ea221be218e012da6804f60232756f151ea6bf940274a4dffa14d8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

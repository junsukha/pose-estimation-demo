{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils # when visualing out poses\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: #.Pose access pose estimation model, #min_tracking_confidence tracks state\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() # frame is image from camera\n",
    "        \n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # save memory\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image) # image here is RGB\n",
    "        \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) # image here is BGR\n",
    "        \n",
    "        cv2.imshow('Mediappipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://mediapipe.dev/images/mobile/pose_tracking_full_body_landmarks.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0.6866485\n",
      "y: 3.2407122\n",
      "z: -0.28079033\n",
      "visibility: 0.0001965116\n",
      "\n",
      "x: 0.5770546\n",
      "y: 3.228321\n",
      "z: -0.3846163\n",
      "visibility: 0.00019784404\n",
      "\n",
      "x: 0.59909403\n",
      "y: 3.2187526\n",
      "z: -0.5045682\n",
      "visibility: 0.00035262943\n",
      "\n",
      "x: 0.6032768\n",
      "y: 3.199051\n",
      "z: -0.45688838\n",
      "visibility: 0.0004213701\n",
      "\n",
      "x: 0.611674\n",
      "y: 3.165591\n",
      "z: -0.44787616\n",
      "visibility: 0.00044142499\n",
      "\n",
      "x: 0.61618567\n",
      "y: 3.1510265\n",
      "z: -0.47874054\n",
      "visibility: 0.00049401773\n",
      "\n",
      "x: 0.6130318\n",
      "y: 3.1083791\n",
      "z: -0.60590255\n",
      "visibility: 0.00055452867\n",
      "\n",
      "x: 0.61392057\n",
      "y: 3.1181302\n",
      "z: -0.52418196\n",
      "visibility: 0.00063266914\n",
      "\n",
      "x: 0.6156391\n",
      "y: 3.127001\n",
      "z: -0.33616063\n",
      "visibility: 0.00063364406\n",
      "\n",
      "x: 0.6041676\n",
      "y: 3.1357262\n",
      "z: -0.36414796\n",
      "visibility: 0.0006108663\n",
      "\n",
      "x: 0.60140836\n",
      "y: 3.0764499\n",
      "z: -0.5666834\n",
      "visibility: 0.00077840703\n",
      "\n",
      "x: 0.60049444\n",
      "y: 3.088856\n",
      "z: -0.5654243\n",
      "visibility: 0.00080842583\n",
      "\n",
      "x: 0.5853381\n",
      "y: 3.0742803\n",
      "z: -0.63075125\n",
      "visibility: 0.0008355924\n",
      "\n",
      "x: 0.60571706\n",
      "y: 3.0887191\n",
      "z: -0.4963166\n",
      "visibility: 0.0008939582\n",
      "\n",
      "x: 0.57305634\n",
      "y: 3.0924447\n",
      "z: -0.4561418\n",
      "visibility: 0.00088726974\n",
      "\n",
      "x: 0.59830487\n",
      "y: 3.0981634\n",
      "z: -0.40850043\n",
      "visibility: 0.0009350591\n",
      "\n",
      "x: 0.5957139\n",
      "y: 3.1158943\n",
      "z: -0.37232\n",
      "visibility: 0.0009557024\n",
      "\n",
      "x: 0.59598047\n",
      "y: 3.052983\n",
      "z: -0.5234703\n",
      "visibility: 0.0010358575\n",
      "\n",
      "x: 0.57058764\n",
      "y: 3.053886\n",
      "z: -0.6169856\n",
      "visibility: 0.0012606714\n",
      "\n",
      "x: 0.56812465\n",
      "y: 3.0608802\n",
      "z: -0.57681656\n",
      "visibility: 0.0012653174\n",
      "\n",
      "x: 0.57023174\n",
      "y: 3.0521786\n",
      "z: -0.5670678\n",
      "visibility: 0.0012673552\n",
      "\n",
      "x: 0.5709672\n",
      "y: 2.8848898\n",
      "z: -0.69749755\n",
      "visibility: 0.0014452477\n",
      "\n",
      "x: 0.5708826\n",
      "y: 2.9485002\n",
      "z: -0.66465497\n",
      "visibility: 0.001607308\n",
      "\n",
      "x: 0.5701637\n",
      "y: 2.9835482\n",
      "z: -0.6219718\n",
      "visibility: 0.001657533\n",
      "\n",
      "x: 0.5708897\n",
      "y: 3.000405\n",
      "z: -0.600461\n",
      "visibility: 0.0016663132\n",
      "\n",
      "x: 0.566102\n",
      "y: 2.9886527\n",
      "z: -0.5998921\n",
      "visibility: 0.0017370092\n",
      "\n",
      "x: 0.55672354\n",
      "y: 2.8551278\n",
      "z: -0.68098277\n",
      "visibility: 0.002021016\n",
      "\n",
      "x: 0.557623\n",
      "y: 2.6591551\n",
      "z: -0.8639983\n",
      "visibility: 0.0023475827\n",
      "\n",
      "x: 0.55866295\n",
      "y: 2.7835457\n",
      "z: -0.7566031\n",
      "visibility: 0.002463352\n",
      "\n",
      "x: 0.5637616\n",
      "y: 2.7036035\n",
      "z: -0.7519799\n",
      "visibility: 0.0026485415\n",
      "\n",
      "x: 0.561766\n",
      "y: 2.600489\n",
      "z: -0.7614986\n",
      "visibility: 0.002742983\n",
      "\n",
      "x: 0.55005175\n",
      "y: 2.6005113\n",
      "z: -0.7513591\n",
      "visibility: 0.0028862406\n",
      "\n",
      "x: 0.54765886\n",
      "y: 2.5956774\n",
      "z: -0.7379797\n",
      "visibility: 0.0029180918\n",
      "\n",
      "x: 0.553587\n",
      "y: 2.4891555\n",
      "z: -0.6610626\n",
      "visibility: 0.002882659\n",
      "\n",
      "x: 0.5570814\n",
      "y: 2.5879753\n",
      "z: -0.7463494\n",
      "visibility: 0.002883811\n",
      "\n",
      "x: 0.56222016\n",
      "y: 2.6186821\n",
      "z: -0.62967974\n",
      "visibility: 0.002801487\n",
      "\n",
      "x: 0.57909894\n",
      "y: 2.9106472\n",
      "z: -0.55294144\n",
      "visibility: 0.0026578847\n",
      "\n",
      "x: 0.58347476\n",
      "y: 2.8631248\n",
      "z: -0.595675\n",
      "visibility: 0.0026325325\n",
      "\n",
      "x: 0.6144489\n",
      "y: 2.9428203\n",
      "z: -0.52063817\n",
      "visibility: 0.0025290556\n",
      "\n",
      "x: 0.58058935\n",
      "y: 2.972429\n",
      "z: -0.714691\n",
      "visibility: 0.0025598228\n",
      "\n",
      "x: 0.571908\n",
      "y: 3.0578406\n",
      "z: -0.7105582\n",
      "visibility: 0.002573427\n",
      "\n",
      "x: 0.5594669\n",
      "y: 2.9408529\n",
      "z: -0.7164927\n",
      "visibility: 0.002602006\n",
      "\n",
      "x: 0.5396976\n",
      "y: 2.7898662\n",
      "z: -0.7265979\n",
      "visibility: 0.0025813386\n",
      "\n",
      "x: 0.5532371\n",
      "y: 2.9319687\n",
      "z: -0.7021748\n",
      "visibility: 0.0026549972\n",
      "\n",
      "x: 0.55176795\n",
      "y: 2.9134538\n",
      "z: -0.7376342\n",
      "visibility: 0.002630636\n",
      "\n",
      "x: 0.55187476\n",
      "y: 2.9531896\n",
      "z: -0.73626953\n",
      "visibility: 0.002723899\n",
      "\n",
      "x: 0.56459165\n",
      "y: 2.9780083\n",
      "z: -0.6551406\n",
      "visibility: 0.0026384227\n",
      "\n",
      "x: 0.59732044\n",
      "y: 3.0640721\n",
      "z: -0.57864916\n",
      "visibility: 0.0025202741\n",
      "\n",
      "x: 0.5901889\n",
      "y: 2.8986495\n",
      "z: -0.5892666\n",
      "visibility: 0.002501993\n",
      "\n",
      "x: 0.53937584\n",
      "y: 2.780876\n",
      "z: -0.6448994\n",
      "visibility: 0.0025676496\n",
      "\n",
      "x: 0.579437\n",
      "y: 2.6829126\n",
      "z: -0.6455404\n",
      "visibility: 0.0025487882\n",
      "\n",
      "x: 0.5738977\n",
      "y: 2.7301161\n",
      "z: -0.70509094\n",
      "visibility: 0.0025778406\n",
      "\n",
      "x: 0.57365954\n",
      "y: 2.9398232\n",
      "z: -0.6808309\n",
      "visibility: 0.002474677\n",
      "\n",
      "x: 0.5602666\n",
      "y: 2.680504\n",
      "z: -0.6692542\n",
      "visibility: 0.0024299547\n",
      "\n",
      "x: 0.5597191\n",
      "y: 2.9100163\n",
      "z: -0.687016\n",
      "visibility: 0.002432321\n",
      "\n",
      "x: 0.60799253\n",
      "y: 3.1601663\n",
      "z: -0.4239196\n",
      "visibility: 0.0022786255\n",
      "\n",
      "x: 0.600922\n",
      "y: 3.0370078\n",
      "z: -0.5187929\n",
      "visibility: 0.0022114494\n",
      "\n",
      "x: 0.596313\n",
      "y: 2.8834739\n",
      "z: -0.59857947\n",
      "visibility: 0.002273786\n",
      "\n",
      "x: 0.6004598\n",
      "y: 3.1154642\n",
      "z: -0.5514414\n",
      "visibility: 0.0021575517\n",
      "\n",
      "x: 0.5864188\n",
      "y: 2.9681704\n",
      "z: -0.6998598\n",
      "visibility: 0.0021552248\n",
      "\n",
      "x: 0.58587325\n",
      "y: 2.9913952\n",
      "z: -0.6881492\n",
      "visibility: 0.0021706363\n",
      "\n",
      "x: 0.58655655\n",
      "y: 2.8283858\n",
      "z: -0.68400085\n",
      "visibility: 0.002136999\n",
      "\n",
      "x: 0.6135898\n",
      "y: 2.8329263\n",
      "z: -0.5491472\n",
      "visibility: 0.0020432393\n",
      "\n",
      "x: 0.6508756\n",
      "y: 3.1512043\n",
      "z: -0.4085906\n",
      "visibility: 0.0019672383\n",
      "\n",
      "x: 0.6377615\n",
      "y: 3.170598\n",
      "z: -0.4387602\n",
      "visibility: 0.0019370483\n",
      "\n",
      "x: 0.6724957\n",
      "y: 3.0975113\n",
      "z: -0.4690033\n",
      "visibility: 0.0018249943\n",
      "\n",
      "x: 0.67582476\n",
      "y: 2.8199966\n",
      "z: -0.67357004\n",
      "visibility: 0.0018840587\n",
      "\n",
      "x: 0.6702391\n",
      "y: 3.0371437\n",
      "z: -0.5119637\n",
      "visibility: 0.0017657893\n",
      "\n",
      "x: 0.6637157\n",
      "y: 2.976135\n",
      "z: -0.490616\n",
      "visibility: 0.0017255219\n",
      "\n",
      "x: 0.6547502\n",
      "y: 3.0194192\n",
      "z: -0.41256872\n",
      "visibility: 0.0017216045\n",
      "\n",
      "x: 0.65117323\n",
      "y: 2.632675\n",
      "z: -0.4444848\n",
      "visibility: 0.0018918883\n",
      "\n",
      "x: 0.6384504\n",
      "y: 2.8250434\n",
      "z: -0.46106228\n",
      "visibility: 0.0018628014\n",
      "\n",
      "x: 0.63266957\n",
      "y: 2.6608686\n",
      "z: -0.47730175\n",
      "visibility: 0.0018547765\n",
      "\n",
      "x: 0.61678827\n",
      "y: 2.6889684\n",
      "z: -0.56203103\n",
      "visibility: 0.0018575584\n",
      "\n",
      "x: 0.6142386\n",
      "y: 2.3633475\n",
      "z: -0.65662456\n",
      "visibility: 0.0020882552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: #.Pose access pose estimation model, #min_tracking_confidence tracks state\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() # frame is image from camera\n",
    "        \n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # save memory\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image) # image here is RGB\n",
    "        \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark # hold landamrks. including x,y,z. Use this for calculating angles\n",
    "            # print(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX])\n",
    "            # Filter out landmarks with low visibility\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) # image here is BGR\n",
    "        \n",
    "        cv2.imshow('Mediappipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mmp_pose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstatic_image_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmodel_complexity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msmooth_landmarks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0menable_segmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msmooth_segmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_detection_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_tracking_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mPose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSolutionBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;34m\"\"\"MediaPipe Pose.\n",
      "\n",
      "  MediaPipe Pose processes an RGB image and returns pose landmarks on the most\n",
      "  prominent person detected.\n",
      "\n",
      "  Please refer to https://solutions.mediapipe.dev/pose#python-solution-api for\n",
      "  usage examples.\n",
      "  \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mstatic_image_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mmodel_complexity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0msmooth_landmarks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0menable_segmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0msmooth_segmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mmin_detection_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mmin_tracking_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Initializes a MediaPipe Pose object.\n",
      "\n",
      "    Args:\n",
      "      static_image_mode: Whether to treat the input images as a batch of static\n",
      "        and possibly unrelated images, or a video stream. See details in\n",
      "        https://solutions.mediapipe.dev/pose#static_image_mode.\n",
      "      model_complexity: Complexity of the pose landmark model: 0, 1 or 2. See\n",
      "        details in https://solutions.mediapipe.dev/pose#model_complexity.\n",
      "      smooth_landmarks: Whether to filter landmarks across different input\n",
      "        images to reduce jitter. See details in\n",
      "        https://solutions.mediapipe.dev/pose#smooth_landmarks.\n",
      "      enable_segmentation: Whether to predict segmentation mask. See details in\n",
      "        https://solutions.mediapipe.dev/pose#enable_segmentation.\n",
      "      smooth_segmentation: Whether to filter segmentation across different input\n",
      "        images to reduce jitter. See details in\n",
      "        https://solutions.mediapipe.dev/pose#smooth_segmentation.\n",
      "      min_detection_confidence: Minimum confidence value ([0.0, 1.0]) for person\n",
      "        detection to be considered successful. See details in\n",
      "        https://solutions.mediapipe.dev/pose#min_detection_confidence.\n",
      "      min_tracking_confidence: Minimum confidence value ([0.0, 1.0]) for the\n",
      "        pose landmarks to be considered tracked successfully. See details in\n",
      "        https://solutions.mediapipe.dev/pose#min_tracking_confidence.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_download_oss_pose_landmark_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_complexity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mbinary_graph_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_BINARYPB_FILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mside_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m'model_complexity'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_complexity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m'smooth_landmarks'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msmooth_landmarks\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstatic_image_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m'enable_segmentation'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0menable_segmentation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m'smooth_segmentation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0msmooth_segmentation\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstatic_image_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m'use_prev_landmarks'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstatic_image_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcalculator_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m'posedetectioncpu__TensorsToDetectionsCalculator.min_score_thresh'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmin_detection_confidence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m'poselandmarkbyroicpu__tensorstoposelandmarksandsegmentation__ThresholdingCalculator.threshold'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmin_tracking_confidence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pose_landmarks'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pose_world_landmarks'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'segmentation_mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mNamedTuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\n",
      "\n",
      "    Args:\n",
      "      image: An RGB image represented as a numpy ndarray.\n",
      "\n",
      "    Raises:\n",
      "      RuntimeError: If the underlying graph throws any error.\n",
      "      ValueError: If the input image is not three channel RGB.\n",
      "\n",
      "    Returns:\n",
      "      A NamedTuple with fields describing the landmarks on the most prominate\n",
      "      person detected:\n",
      "        1) \"pose_landmarks\" field that contains the pose landmarks.\n",
      "        2) \"pose_world_landmarks\" field that contains the pose landmarks in\n",
      "        real-world 3D coordinates that are in meters with the origin at the\n",
      "        center between hips.\n",
      "        3) \"segmentation_mask\" field that contains the segmentation mask if\n",
      "           \"enable_segmentation\" is set to true.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pytype: disable=attribute-error\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pytype: disable=attribute-error\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mlandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClearField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'presence'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_world_landmarks\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pytype: disable=attribute-error\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_world_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pytype: disable=attribute-error\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mlandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClearField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'presence'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\junsu\\anaconda3\\envs\\3d-body-demo\\lib\\site-packages\\mediapipe\\python\\solutions\\pose.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "mp_pose.Pose??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.6142386\n",
       "y: 2.3633475\n",
       "z: -0.65662456\n",
       "visibility: 0.0020882552"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value] # why does this have value even tho it didn't detect it. if visiblility is low, don't save the position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.62809384\n",
       "y: 1.1210781\n",
       "z: -0.37526324\n",
       "visibility: 0.41440323"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.6687571\n",
       "y: 1.2022107\n",
       "z: -0.8656362\n",
       "visibility: 0.36659306"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.5560192\n",
       "y: 1.0103874\n",
       "z: -1.1541002\n",
       "visibility: 0.3021175"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # Frist\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1] - b[1], c[0] -b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0/np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "        \n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: #.Pose access pose estimation model, #min_tracking_confidence tracks state\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() # frame is image from camera\n",
    "        \n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # save memory\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image) # image here is RGB\n",
    "        \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark # hold landamrks. including x,y,z. Use this for calculating angles\n",
    "            # print(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX])\n",
    "            # Filter out landmarks with low visibility\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]    \n",
    "            \n",
    "            # hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            # shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            # elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]   \n",
    "            \n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualize\n",
    "            cv2.putText(image, \n",
    "                        str(angle),\n",
    "                        tuple(np.multiply(elbow, [640, 480]).astype(int)), # controal [640, 480] to window size\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) # image here is BGR\n",
    "        \n",
    "        cv2.imshow('Mediappipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curl Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Curl counter variables\n",
    "counter = 0\n",
    "stage = None\n",
    "## setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: #.Pose access pose estimation model, #min_tracking_confidence tracks state\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read() # frame is image from camera\n",
    "        \n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # save memory\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image) # image here is RGB\n",
    "        \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark # hold landamrks. including x,y,z. Use this for calculating angles\n",
    "            # print(landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX])\n",
    "            # Filter out landmarks with low visibility\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]    \n",
    "            \n",
    "            # hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            # shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            # elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]   \n",
    "            \n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualize\n",
    "            cv2.putText(image, \n",
    "                        str(angle),\n",
    "                        tuple(np.multiply(elbow, [640, 480]).astype(int)), # controal [640, 480] to window size\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "            if angle < 30 and stage == 'down':\n",
    "                stage = 'up'\n",
    "                counter += 1\n",
    "                print(counter) \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render curl counter\n",
    "        cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "        \n",
    "        cv2.putText(image, 'REPS', (15,20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        cv2.putText(image, str(counter),\n",
    "                    (10,70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) # image here is BGR\n",
    "        \n",
    "        cv2.imshow('Mediappipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('3d-body-demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "027937559ea221be218e012da6804f60232756f151ea6bf940274a4dffa14d8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
